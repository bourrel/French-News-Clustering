{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBGDeeP7atmL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from transformers import FlaubertTokenizer\n",
    "from transformers.modeling_tf_flaubert import TFFlaubertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "SEQUENCE_LENGTH = 64\n",
    "ROOT_FOLDER = os.path.abspath(os.path.join(os.getcwd(), os.pardir)) + \"/\"\n",
    "MODEL_PATH = ROOT_FOLDER + \"models/\"\n",
    "DATASET_PATH = ROOT_FOLDER + \"dataset/\"\n",
    "LOG_PATH = ROOT_FOLDER + \"logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qyjNf9r3atmX"
   },
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encoder class label by alphabetical order\n",
    "labels = ['culture', 'france', 'international', 'santé', 'science_high-tech', 'sports', 'économie']\n",
    "loss_weights=[[2.0014090613483635/21.57126168224299, 1.5277059590046953/21.57126168224299, 1.853869129790919/21.57126168224299, 21.57126168224299/21.57126168224299, 3.844472204871955/21.57126168224299, 1.0/21.57126168224299, 3.357883251500273/21.57126168224299]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='error', sparse=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit([[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 1. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 1. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 1. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Print encoder values to make sure they are ordonned as label order\n",
    "print(enc.transform([[\"culture\"]]).toarray())\n",
    "print(enc.transform([[\"france\"]]).toarray())\n",
    "print(enc.transform([[\"international\"]]).toarray())\n",
    "print(enc.transform([[\"santé\"]]).toarray())\n",
    "print(enc.transform([[\"science_high-tech\"]]).toarray())\n",
    "print(enc.transform([[\"sports\"]]).toarray())\n",
    "print(enc.transform([[\"économie\"]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_category(dictOfNames):\n",
    "    new_dict = {}\n",
    "    try:\n",
    "        for (key,value) in dictOfNames.items():\n",
    "            #if \"score\" in key or \"applenews\" in key or \"homepage\" in key:\n",
    "            #    continue\n",
    "            new_key = re.sub(r'desktop_|mobile_webview_', \"\", key)\n",
    "            new_key = re.sub(r'google_', \"\", new_key)\n",
    "            if new_key not in labels:\n",
    "                continue\n",
    "            if new_key not in new_dict:\n",
    "                new_dict[new_key] = 0\n",
    "            new_dict[new_key] += value\n",
    "        #return [key for key in new_dict.keys()]\n",
    "        return max(new_dict, key=new_dict.get)\n",
    "    except ValueError as e :\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# lines :  553030\n"
     ]
    }
   ],
   "source": [
    "lines = open(DATASET_PATH + 'since_january.csv').readlines()\n",
    "lines = lines[1:]\n",
    "random.shuffle(lines)\n",
    "print(\"# lines : \", len(lines))\n",
    "open(DATASET_PATH + 'shuffled_since_january.csv', 'w').writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_generator():\n",
    "    samples = []\n",
    "    categories = []\n",
    "    idx = 0\n",
    "    while 1:\n",
    "        with open(DATASET_PATH + 'shuffled_since_january.csv', 'r', newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "            idx = 0\n",
    "            for i, row in enumerate(reader):\n",
    "                if len(row) < 3 or row[3] not in labels:\n",
    "                    continue\n",
    "\n",
    "                text = row[0]\n",
    "                category = \"\"\n",
    "                if row[4] != {} and row[4] != \"\":\n",
    "                    category = get_main_category(json.loads(row[4]))\n",
    "                if category == \"\":\n",
    "                    continue\n",
    "\n",
    "                samples.append(tokenizer.encode(text, max_length=SEQUENCE_LENGTH, pad_to_max_length=SEQUENCE_LENGTH, add_special_tokens=True))\n",
    "                categories.append([category])\n",
    "\n",
    "                idx += 1\n",
    "                if idx >= BATCH_SIZE:\n",
    "                    categories = enc.transform(categories).toarray()\n",
    "                    yield tf.convert_to_tensor(samples, dtype=tf.int32), tf.convert_to_tensor(categories, dtype=tf.int32)\n",
    "                    samples = []\n",
    "                    categories = []\n",
    "                    idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ki-ztvyKatmQ"
   },
   "source": [
    "## Import camembert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPFITcsIatmR"
   },
   "outputs": [],
   "source": [
    "model = TFFlaubertForSequenceClassification.from_pretrained(\n",
    "    \"jplu/tf-flaubert-base-cased\",\n",
    "    num_labels=len(labels),\n",
    "    max_length=SEQUENCE_LENGTH,\n",
    "    #force_download=True\n",
    ")\n",
    "\n",
    "tokenizer = FlaubertTokenizer.from_pretrained(\"jplu/tf-flaubert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aHDtNl43atmU",
    "outputId": "e9b3c96e-b085-450f-d733-b73bcb6a14db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
      "array([[ 0.95408237, -0.28413275,  1.5128503 , -0.20761025, -0.40679094,\n",
      "         0.50068426, -0.0023958 ]], dtype=float32)>,)\n",
      "2\n",
      "international\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Sida. Une start-up française découvre une avancée majeure dans la lutte contre le VIH\", return_tensors='tf')#, add_special_tokens=True, pad_to_max_length=, return_tensors='tf')\n",
    "out = model(input_ids)\n",
    "\n",
    "#print(input_ids)\n",
    "print(out)\n",
    "print(np.argmax(np.abs(out[0])))\n",
    "print(labels[np.argmax(np.abs(out[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]], shape=(8, 7), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]], shape=(8, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for idx, (a, b) in enumerate(file_generator()):\n",
    "    if idx > 1:\n",
    "        break\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agGTsSo9atmm"
   },
   "source": [
    "## Train model on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_flaubert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequence_summary (TFSequence multiple                  5383      \n",
      "_________________________________________________________________\n",
      "transformer (TFFlaubertMainL multiple                  138233088 \n",
      "=================================================================\n",
      "Total params: 138,238,471\n",
      "Trainable params: 138,238,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=LOG_PATH+\"flaubert_cased_\"+time.strftime(\"%d%m%y/%H:%M:%S\"))\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(MODEL_PATH+\"checkpoints/\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[metric],\n",
    "    loss_weights=loss_weights\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 200 steps, validate for 10 steps\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 45s 224ms/step - loss: 0.3472 - accuracy: 0.4381 - val_loss: 0.1511 - val_accuracy: 0.8250\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 0.1779 - accuracy: 0.7681 - val_loss: 0.1237 - val_accuracy: 0.7875\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.1535 - accuracy: 0.7837 - val_loss: 0.0765 - val_accuracy: 0.8875\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 0.1358 - accuracy: 0.8281 - val_loss: 0.1277 - val_accuracy: 0.8500\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 0.1358 - accuracy: 0.8031 - val_loss: 0.0661 - val_accuracy: 0.9125\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 0.1139 - accuracy: 0.8413 - val_loss: 0.1287 - val_accuracy: 0.8375\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1218 - accuracy: 0.8294 - val_loss: 0.0779 - val_accuracy: 0.9000\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1112 - accuracy: 0.8469 - val_loss: 0.1336 - val_accuracy: 0.8250\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1168 - accuracy: 0.8462 - val_loss: 0.0904 - val_accuracy: 0.8750\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1199 - accuracy: 0.8419 - val_loss: 0.0438 - val_accuracy: 0.9625\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1044 - accuracy: 0.8575 - val_loss: 0.0534 - val_accuracy: 0.9125\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1099 - accuracy: 0.8519 - val_loss: 0.1000 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0958 - accuracy: 0.8731 - val_loss: 0.0699 - val_accuracy: 0.8875\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1180 - accuracy: 0.8338 - val_loss: 0.0912 - val_accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1025 - accuracy: 0.8531 - val_loss: 0.1016 - val_accuracy: 0.8875\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1070 - accuracy: 0.8481 - val_loss: 0.0703 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1005 - accuracy: 0.8719 - val_loss: 0.0808 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1003 - accuracy: 0.8662 - val_loss: 0.0381 - val_accuracy: 0.9250\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1046 - accuracy: 0.8619 - val_loss: 0.0790 - val_accuracy: 0.8875\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0928 - accuracy: 0.8744 - val_loss: 0.0966 - val_accuracy: 0.8875\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1118 - accuracy: 0.8506 - val_loss: 0.0776 - val_accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1053 - accuracy: 0.8562 - val_loss: 0.0709 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0994 - accuracy: 0.8556 - val_loss: 0.0794 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1000 - accuracy: 0.8587 - val_loss: 0.1229 - val_accuracy: 0.8500\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0923 - accuracy: 0.8744 - val_loss: 0.0892 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0932 - accuracy: 0.8769 - val_loss: 0.0739 - val_accuracy: 0.8875\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1029 - accuracy: 0.8594 - val_loss: 0.1053 - val_accuracy: 0.8875\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.0910 - accuracy: 0.8744 - val_loss: 0.0932 - val_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.0979 - accuracy: 0.8612 - val_loss: 0.0930 - val_accuracy: 0.8625\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0993 - accuracy: 0.8662 - val_loss: 0.0797 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0982 - accuracy: 0.8681 - val_loss: 0.0589 - val_accuracy: 0.9125\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0919 - accuracy: 0.8631 - val_loss: 0.0977 - val_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0961 - accuracy: 0.8650 - val_loss: 0.0834 - val_accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0949 - accuracy: 0.8669 - val_loss: 0.0766 - val_accuracy: 0.8875\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0995 - accuracy: 0.8650 - val_loss: 0.0680 - val_accuracy: 0.9250\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0945 - accuracy: 0.8737 - val_loss: 0.0809 - val_accuracy: 0.8875\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0907 - accuracy: 0.8675 - val_loss: 0.0902 - val_accuracy: 0.8875\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0888 - accuracy: 0.8750 - val_loss: 0.0594 - val_accuracy: 0.9250\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0858 - accuracy: 0.8700 - val_loss: 0.0769 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0918 - accuracy: 0.8662 - val_loss: 0.0838 - val_accuracy: 0.8625\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0858 - accuracy: 0.8844 - val_loss: 0.0822 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0895 - accuracy: 0.8763 - val_loss: 0.0808 - val_accuracy: 0.8750\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0885 - accuracy: 0.8781 - val_loss: 0.0461 - val_accuracy: 0.9125\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0852 - accuracy: 0.8825 - val_loss: 0.0677 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0905 - accuracy: 0.8712 - val_loss: 0.0475 - val_accuracy: 0.9250\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0953 - accuracy: 0.8587 - val_loss: 0.0548 - val_accuracy: 0.9125\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0855 - accuracy: 0.8800 - val_loss: 0.1115 - val_accuracy: 0.8125\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0900 - accuracy: 0.8800 - val_loss: 0.0807 - val_accuracy: 0.8625\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0874 - accuracy: 0.8856 - val_loss: 0.0753 - val_accuracy: 0.9000\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0823 - accuracy: 0.8894 - val_loss: 0.0985 - val_accuracy: 0.8375\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0822 - accuracy: 0.8869 - val_loss: 0.0535 - val_accuracy: 0.9500\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0853 - accuracy: 0.8763 - val_loss: 0.0826 - val_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0874 - accuracy: 0.8906 - val_loss: 0.0549 - val_accuracy: 0.9125\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0805 - accuracy: 0.8925 - val_loss: 0.0490 - val_accuracy: 0.9500\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0825 - accuracy: 0.8931 - val_loss: 0.1153 - val_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0916 - accuracy: 0.8775 - val_loss: 0.0541 - val_accuracy: 0.9500\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0811 - accuracy: 0.8856 - val_loss: 0.0341 - val_accuracy: 0.9500\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0804 - accuracy: 0.8981 - val_loss: 0.0617 - val_accuracy: 0.8625\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0881 - accuracy: 0.8737 - val_loss: 0.0612 - val_accuracy: 0.9125\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0835 - accuracy: 0.8888 - val_loss: 0.0635 - val_accuracy: 0.9375\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0929 - accuracy: 0.8781 - val_loss: 0.0943 - val_accuracy: 0.8875\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0871 - accuracy: 0.8850 - val_loss: 0.0573 - val_accuracy: 0.9250\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1029 - accuracy: 0.8694 - val_loss: 0.1014 - val_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0914 - accuracy: 0.8788 - val_loss: 0.0822 - val_accuracy: 0.8875\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0941 - accuracy: 0.8775 - val_loss: 0.0209 - val_accuracy: 0.9750\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0868 - accuracy: 0.8806 - val_loss: 0.0534 - val_accuracy: 0.9375\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0925 - accuracy: 0.8725 - val_loss: 0.0721 - val_accuracy: 0.8875\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0896 - accuracy: 0.8763 - val_loss: 0.0827 - val_accuracy: 0.8750\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0929 - accuracy: 0.8888 - val_loss: 0.0682 - val_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0976 - accuracy: 0.8681 - val_loss: 0.0641 - val_accuracy: 0.9250\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0952 - accuracy: 0.8712 - val_loss: 0.0544 - val_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0826 - accuracy: 0.8875 - val_loss: 0.1376 - val_accuracy: 0.8625\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0819 - accuracy: 0.8938 - val_loss: 0.0739 - val_accuracy: 0.8750\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0835 - accuracy: 0.8881 - val_loss: 0.0774 - val_accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0831 - accuracy: 0.8831 - val_loss: 0.0760 - val_accuracy: 0.9125\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.0798 - accuracy: 0.8956 - val_loss: 0.0446 - val_accuracy: 0.9250\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0815 - accuracy: 0.8794 - val_loss: 0.0840 - val_accuracy: 0.8875\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0915 - accuracy: 0.8763 - val_loss: 0.0836 - val_accuracy: 0.9125\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0796 - accuracy: 0.8938 - val_loss: 0.0773 - val_accuracy: 0.8875\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0827 - accuracy: 0.8938 - val_loss: 0.0630 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0824 - accuracy: 0.8900 - val_loss: 0.0579 - val_accuracy: 0.8750\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0862 - accuracy: 0.8863 - val_loss: 0.0699 - val_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0834 - accuracy: 0.8856 - val_loss: 0.0626 - val_accuracy: 0.9000\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0862 - accuracy: 0.8881 - val_loss: 0.0921 - val_accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0827 - accuracy: 0.8894 - val_loss: 0.0372 - val_accuracy: 0.9250\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0861 - accuracy: 0.8913 - val_loss: 0.0472 - val_accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0811 - accuracy: 0.8900 - val_loss: 0.0734 - val_accuracy: 0.8750\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0904 - accuracy: 0.8825 - val_loss: 0.0690 - val_accuracy: 0.9125\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0785 - accuracy: 0.8969 - val_loss: 0.0673 - val_accuracy: 0.9000\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0888 - accuracy: 0.8806 - val_loss: 0.0920 - val_accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0813 - accuracy: 0.8894 - val_loss: 0.0810 - val_accuracy: 0.8750\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0812 - accuracy: 0.8931 - val_loss: 0.0714 - val_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0774 - accuracy: 0.8938 - val_loss: 0.0498 - val_accuracy: 0.9000\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0848 - accuracy: 0.8931 - val_loss: 0.0587 - val_accuracy: 0.9125\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0813 - accuracy: 0.8938 - val_loss: 0.0598 - val_accuracy: 0.9125\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0918 - accuracy: 0.8750 - val_loss: 0.0786 - val_accuracy: 0.8875\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0844 - accuracy: 0.8881 - val_loss: 0.0582 - val_accuracy: 0.9125\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0852 - accuracy: 0.8850 - val_loss: 0.0609 - val_accuracy: 0.9000\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0850 - accuracy: 0.8838 - val_loss: 0.0523 - val_accuracy: 0.9375\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0767 - accuracy: 0.8963 - val_loss: 0.1168 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f29dc7ec7d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    file_generator(),\n",
    "    epochs=100,\n",
    "    max_queue_size=2,\n",
    "    steps_per_epoch=200,\n",
    "    validation_data=file_generator(),\n",
    "    validation_steps=10,\n",
    "    #callbacks=[checkpoint] # tensorboard\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHke8uQhatms"
   },
   "outputs": [],
   "source": [
    "input_ids = tf.constant(\n",
    "    [\n",
    "        tokenizer.encode(\n",
    "            clean_text(\"PSG : Incroyable, le Real a réellement renoncé à Mbappé !\"),\n",
    "            add_special_tokens=True\n",
    "        ),\n",
    "    ], tf.int32\n",
    ")\n",
    "out = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNqWse-4emRO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
      "array([[-1.5705025 , -0.8648224 ,  0.33070713, -4.861527  , -1.0947516 ,\n",
      "         6.9560866 , -0.41979995]], dtype=float32)>,)\n",
      "5\n",
      "sports\n",
      "['culture', 'france', 'international', 'santé', 'science_high-tech', 'sports', 'économie']\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "print(np.argmax(np.abs(out[0])))\n",
    "print(list(labels)[np.argmax(np.abs(out[0]))])\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 5]]\n",
      "Classification Report\n",
      "Confusion Matrix\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 0 3 1]\n",
      " [0 0 0 0 0]]\n",
      "Classification Report\n",
      "Confusion Matrix\n",
      "[[2 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 2]]\n",
      "Classification Report\n"
     ]
    }
   ],
   "source": [
    "for idx, (X_test, y_test) in enumerate(file_generator()):\n",
    "    if idx > 2:\n",
    "        break\n",
    "    #Confution Matrix and Classification Report\n",
    "    Y_pred = model(X_test)\n",
    "\n",
    "    y_pred = [labels[int(np.argmax(y))] for y in Y_pred[0]]\n",
    "    #for (a, b) in zip(X_test, y_pred):\n",
    "    #    print(b, \":\", tokenizer.decode(a, skip_special_tokens=True))\n",
    "    y_test = enc.inverse_transform(y_test.numpy())\n",
    "\n",
    "    #for x, y in zip(y_test, y_pred):\n",
    "    #    print(x, \"/\", y)\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('Classification Report')\n",
    "\n",
    "    #print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(MODEL_PATH+\"last_model\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Import && train model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
